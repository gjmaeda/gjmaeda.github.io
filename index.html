<!DOCTYPE html>
<html  >
<head>
  <!-- Site made with Mobirise Website Builder v5.3.5, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v5.3.5, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/icon2.gif" type="image/x-icon">
  <meta name="description" content="Robotics researcher">
  
  
  <title>Guilherme Maeda</title>
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons/mobirise-icons.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/tether/tether.min.css">
  <link rel="stylesheet" href="assets/dropdown/css/style.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Rubik:300,300i,400,400i,500,500i,700,700i,900,900i&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Rubik:300,300i,400,400i,500,500i,700,700i,900,900i&display=swap"></noscript>
  <link rel="preload" as="style" href="assets/mobirise/css/mbr-additional.css"><link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css" type="text/css">
  
  
  
  
</head>
<body>
  
  <section class="menu cid-qTkzRZLJNu" once="menu" id="menu1-0">

    

    <nav class="navbar navbar-expand beta-menu navbar-dropdown align-items-center navbar-fixed-top navbar-toggleable-sm">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <div class="hamburger">
                <span></span>
                <span></span>
                <span></span>
                <span></span>
            </div>
        </button>
        <div class="menu-logo">
            <div class="navbar-brand">
                <span class="navbar-logo">
                    <a href="index.html">
                         <img src="assets/images/icon2.gif" alt="Mobirise" title="" style="height: 3.8rem;">
                    </a>
                </span>
                <span class="navbar-caption-wrap"><a class="navbar-caption text-white display-4" href="index.html">Home</a></span>
            </div>
        </div>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav nav-dropdown nav-right" data-app-modern-menu="true"><li class="nav-item dropdown">
                    <a class="nav-link link text-white dropdown-toggle display-4" href="publications.html" data-toggle="dropdown-submenu" aria-expanded="true"><span class="mbri-pages mbr-iconfont mbr-iconfont-btn"></span>Publications</a><div class="dropdown-menu"><a class="text-white dropdown-item display-4" href="publications.html" target="_blank">Publication list</a><a class="text-white dropdown-item display-4" href="https://scholar.google.co.jp/citations?user=fVCyyDgAAAAJ&hl=en" target="_blank" aria-expanded="false">Google Scholar</a></div>
                </li><li class="nav-item dropdown"><a class="nav-link link text-white dropdown-toggle display-4" href="about.html" data-toggle="dropdown-submenu" aria-expanded="false"><span class="mbri-user mbr-iconfont mbr-iconfont-btn"></span>
                        
                        About</a><div class="dropdown-menu"><a class="text-white dropdown-item display-4" href="about.html">Bio and contact</a><a class="text-white dropdown-item display-4" href="./pdf/resume_gjmaeda.pdf" target="_blank" aria-expanded="false">CV</a></div></li></ul>
            
        </div>
    </nav>
</section>

<section class="header1 cid-rJBn3T8pcH" id="header16-10">

    

    <div class="mbr-overlay" style="opacity: 0.5; background-color: rgb(255, 255, 255);">
    </div>

    <div class="container">
        <div class="row justify-content-md-center">
            <div class="col-md-10 align-center">
                
                <h3 class="mbr-section-subtitle mbr-light pb-3 mbr-fonts-style display-5">Guilherme Maeda
<div><a href="https://preferred.jp/en/" target="_blank">Preferred Networks</a>&nbsp;researcher in robotics and robot motor skill learning
</div><div>
</div><div><strong><br></strong></div><strong><br></strong><div>Eventually, our society will depend on robots as general-purpose helpers that will assist us throughout our entire lives. This vision requires robots capable of learning skills by themselves to manipulate and interact with the world in a way that is useful for us. To this end, my work involves the investigation and design of learning control methods, and their implementation and validation using real robots.&nbsp;<br><br><br></div></h3>
                
                
            </div>
        </div>
    </div>

</section>

<section class="mbr-section content4 cid-rJNkonYHDL" id="content4-2s">

    

    <div class="container">
        <div class="media-container-row">
            <div class="title col-12 col-md-8">
                
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-2">News and upates</h3>
                
            </div>
        </div>
    </div>
</section>

<section class="mbr-section article content11 cid-rJpusLPIWd" id="content11-7">
     

    <div class="container">
        <div class="media-container-row">
            <div class="mbr-text counter-container col-12 col-md-8 mbr-fonts-style display-7">
                <ol>
                    </ol><p><br></p><ol><li>April 2021. Acting as area chair for<a href="https://www.robot-learning.org/" class="text-primary" target="_blank"> CoRL 2021</a></li><li>In August 2020 I am giving an invited (online) talk at the <a href="https://www.ias.informatik.tu-darmstadt.de/" target="_blank">IAS </a>group in TU Darmstadt on our <a href="https://arxiv.org/pdf/1912.03535.pdf" target="_blank">new movement primitive formulation</a>.</li><li>July 2020. The virtual RSS workshop was held on the 13th of July 2020 with great success and many lessons learned! We will update it with some conclusions soon. "<a href="https://sites.google.com/cs.washington.edu/rss-2020-service-robots/home" target="_blank">Closing the Academia to Real-World Gap in Service Robotics</a>". You can watch the entire live sessions <a href="https://www.youtube.com/watch?v=6JMHnpn0Gxs&t=3431s" target="_blank">here</a>.</li><li>July 2020. Our paper "Visual Task Progress Estimation with Appearance Invariant Embeddings for Robot Control and Planning" was accepted at IROS 2020. Pre-print (to be updated) here !</li></ol><p><span style="font-size: 1rem;"><br></span></p><p><span style="font-size: 1rem;">Past news and updates [</span><a href="past.html" style="font-size: 1rem; background-color: rgb(239, 239, 239);">here</a><span style="font-size: 1rem;">].</span><br></p><ol>
                </ol>
            </div>
        </div>
    </div>
</section>

<section class="mbr-section content4 cid-rJNjOuA7F2" id="content4-2r">

    

    <div class="container">
        <div class="media-container-row">
            <div class="title col-12 col-md-8">
                
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-2">Research overview</h3>
                
            </div>
        </div>
    </div>
</section>

<section class="carousel slide cid-rUGeOQF9Fa" data-interval="false" id="slider1-3j">

    

    <div class="full-screen"><div class="mbr-slider slide carousel" data-keyboard="false" data-ride="false" data-interval="false" data-pause="false"><div class="carousel-inner" role="listbox"><div class="carousel-item slider-fullscreen-image" data-bg-video-slide="https://youtu.be/RTldcD3wWfM"><div class="mbr-overlay" style="opacity: 0.4;"></div><div class="container container-slide"><div class="image_wrapper"><div class="carousel-caption justify-content-center"><div class="col-10 align-left"><h2 class="mbr-fonts-style display-2">Phase Portrait Movement Primitives<br><br></h2><p class="lead mbr-text mbr-fonts-style display-5">Animals plan complex motor actions not only fast but seemingly with little effort even on unseen tasks. This natural sense of time and coordination motivates us to approach robot control from a motor skill learning perspective to design fast and computationally light controllers that can be learned autonomously by the robot under mild modeling assumptions.  
<br>
<br>We propose Phase Portrait Movement Primitives. A new primitive representation that includes a phase predictor that can be trained to adapt the timings of the robot's actions. We tested the method on a task comprising 20 degrees-of-freedom using a hydraulic upper body humanoid.&nbsp;</p><div class="mbr-section-btn" buttons="0"><a class="btn display-4 btn-white-outline" href="ppmp.html" target="_blank">Click here for details and videos (2020)</a>   </div></div></div></div></div></div><div class="carousel-item slider-fullscreen-image" data-bg-video-slide="false" style="background-image: url(assets/images/large-screen-shot3-1906x857.jpg);"><div class="container container-slide"><div class="image_wrapper"><div class="mbr-overlay" style="opacity: 0.7; background-color: rgb(35, 35, 35);"></div><img src="assets/images/large-screen-shot3-1906x857.jpg" alt="" title=""><div class="carousel-caption justify-content-center"><div class="col-10 align-left"><h2 class="mbr-fonts-style display-2">Active Incremental Learning of Robot Movement Primitives<br><br></h2><p class="lead mbr-text mbr-fonts-style display-5">Robots must be capable of learning new tasks incrementally, via demonstrations. The problem then is to decide when the user should teach the robot a new skill, or when to trust the robot generalizing its own actions. In this paper, we propose a method where the robot actively make such decisions by quantifying the suitability of its own skill set for a given query via Gaussian Processes. 
<br>
<br>In this <a href="https://youtu.be/s9kG_IKzqO4?t=4" target="_blank">video </a>you can see a robot indicating to the user which demonstrations should be provided to increase its repertoire of skills. The experiment also shows that the robot becomes confident in reaching objects for whose demonstrations were never provided, by incrementally learning from the neighboring demonstrations. &nbsp;</p><div class="mbr-section-btn" buttons="0"><a class="btn display-4 btn-white-outline" href="./pdf/maedaActiveIncrementalLearning2017.pdf" target="_blank">CoRL 2017 paper</a> </div></div></div></div></div></div><div class="carousel-item slider-fullscreen-image" data-bg-video-slide="https://youtu.be/Fpcd2eQBHSM"><div class="mbr-overlay" style="opacity: 0.3;"></div><div class="container container-slide"><div class="image_wrapper"><div class="carousel-caption justify-content-center"><div class="col-10 align-left"><h2 class="mbr-fonts-style display-2">Reinforcement Learning of Motor Skills using Policy Search and Human Corrective Advice<br><br></h2><p class="lead mbr-text mbr-fonts-style display-5">A research project led by Carlos Celemin (now at TU Delft) regarding a human-in-the-loop approach where human feedback can come at any time during the execution of an exploration roll-out. The human feedback can also come sporadically, where most of the roll-outs do not even need to include human feedback. This human feedback is seamlessly incorporated into the policy update as an informed/biased exploration noise. The learning rate increases by factors of 4 to 40 times depending on the task. You can find the details of method in the journal.</p><div class="mbr-section-btn" buttons="0"><a class="btn display-4 btn-white-outline" href="./pdf/celeminReinforcementLearningMotor2019.pdf" target="_blank">IJRR 2019 article</a> </div></div></div></div></div></div><div class="carousel-item slider-fullscreen-image" data-bg-video-slide="https://youtu.be/-6CwUHg32lE"><div class="mbr-overlay" style="opacity: 0.4;"></div><div class="container container-slide"><div class="image_wrapper"><div class="carousel-caption justify-content-center"><div class="col-10 align-left"><h2 class="mbr-fonts-style display-2">Interaction ProMPs for Human-Robot Collaboration <br><br></h2><p class="lead mbr-text mbr-fonts-style display-5">&nbsp;An interaction learning method for collaborative and assistive robots based on movement primitives. Our method allows for both action recognition and human–robot movement coordination. It uses imitation learning to construct a mixture model of human–robot interaction primitives. This probabilistic model allows the assistive trajectory of the robot to be inferred from human observations. 
<br><br></p><div class="mbr-section-btn" buttons="0"><a class="btn display-4 btn-white-outline" href="./pdf/Maeda2017AURO.pdf" target="_blank"> introducing Interaction ProMP (AURO 2015 article)&nbsp;</a> <a class="btn btn-white-outline display-4" href="./pdf/maeda_phase2017_IJRR.pdf" target="_blank">Action recognition with Interaction ProMPs (IJRR 2017 article)</a></div></div></div></div></div></div><div class="carousel-item slider-fullscreen-image active" data-bg-video-slide="https://youtu.be/NWdLHAH4fSQ"><div class="mbr-overlay" style="opacity: 0.4;"></div><div class="container container-slide"><div class="image_wrapper"><div class="carousel-caption justify-content-center"><div class="col-10 align-left"><h2 class="mbr-fonts-style display-2">Visual Task Progress Estimation with Appearance Invariant
 Embeddings for Robot Control and Planning<br><br></h2><p class="lead mbr-text mbr-fonts-style display-5">This work uses the consistency of the progress among different examples and viewpoints of a task to train a deep neural network to map images into measurable features. Our method builds upon Time-Contrastive Networks (TCNs), originally proposed as a representation for continuous visuomotor skill learning, to train the network using only discrete snapshots taken at different stages of a task. The intent is to make the network sensitive to differences in task phases. We associate these embeddings to a sequence of images representing gradual task accomplishment, allowing a robot to iteratively query its motion planner with the current visual state to solve long-horizon tasks. <br></p><div class="mbr-section-btn" buttons="0"><a class="btn display-4 btn-white-outline" href="https://arxiv.org/pdf/2003.06977" target="_blank"> Pre-print 2020</a> <a class="btn display-4 btn-white-outline" href="./research/invariant_task_progress_estimation/task_progress_estimation_1min.mp4" target="_blank"> video</a> </div></div></div></div></div></div></div><a data-app-prevent-settings="" class="carousel-control carousel-control-prev" role="button" data-slide="prev" href="#slider1-3j"><span aria-hidden="true" class="mbri-left mbr-iconfont"></span><span class="sr-only">Previous</span></a><a data-app-prevent-settings="" class="carousel-control carousel-control-next" role="button" data-slide="next" href="#slider1-3j"><span aria-hidden="true" class="mbri-right mbr-iconfont"></span><span class="sr-only">Next</span></a></div></div>

</section><section style="background-color: #fff; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif; color:#aaa; font-size:12px; padding: 0; align-items: center; display: flex;"><a href="https://mobirise.site/d" style="flex: 1 1; height: 3rem; padding-left: 1rem;"></a><p style="flex: 0 0 auto; margin:0; padding-right:1rem;">Built with <a href="https://mobirise.site/a" style="color:#aaa;">Mobirise</a></p></section><script src="assets/web/assets/jquery/jquery.min.js"></script>  <script src="assets/popper/popper.min.js"></script>  <script src="assets/bootstrap/js/bootstrap.min.js"></script>  <script src="assets/tether/tether.min.js"></script>  <script src="assets/smoothscroll/smooth-scroll.js"></script>  <script src="assets/dropdown/js/nav-dropdown.js"></script>  <script src="assets/dropdown/js/navbar-dropdown.js"></script>  <script src="assets/touchswipe/jquery.touch-swipe.min.js"></script>  <script src="assets/ytplayer/jquery.mb.ytplayer.min.js"></script>  <script src="assets/vimeoplayer/jquery.mb.vimeo_player.js"></script>  <script src="assets/bootstrapcarouselswipe/bootstrap-carousel-swipe.js"></script>  <script src="assets/theme/js/script.js"></script>  <script src="assets/slidervideo/script.js"></script>  
  
  
</body>
</html>