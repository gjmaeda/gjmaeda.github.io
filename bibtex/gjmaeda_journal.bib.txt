
@article{lioutikovLearningAttributeGrammars2019,
  title = {Learning {{Attribute Grammars}} for {{Movement Primitive Sequencing}}},
  number = {In press.},
  journal = {The International Journal of Robotics Research (IJRR)},
  doi = {10.1177/0278364919868279.},
  author = {Lioutikov, Rudolf and Maeda, Guilherme and Veiga, Filipe and Kersting, Kristian and Peters, Jan},
  year = {2019},
  file = {/zoteropdf/pdf/lioutikov2019grammarIJRR.pdf}
}

@article{kocOptimizingExecutionDynamic2019,
  title = {Optimizing the {{Execution}} of {{Dynamic Robot Movements}} with {{Learning Control}}},
  volume = {35},
  number = {4},
  journal = {Transaction on Robotics (TRO)},
  doi = {10.1109/TRO.2019.2906558},
  author = {Koc, Okan and Maeda, Guilherme and Peters, Jan},
  year = {2019},
  pages = {909--924},
  file = {/zoteropdf/pdf/kocOptimizingExecutionDynamic2019.pdf;/zoteropdf/pdf/okanTRO209preprint.pdf}
}

@article{ewertonAssistingMovementTraining2018,
  title = {Assisting {{Movement Training}} and {{Execution}} with {{Visual}} and {{Haptic Feedback}}},
  volume = {12},
  journal = {Frontiers in neurorobotics},
  author = {Ewerton, M. and Rother, D. and Weimar, J. and Kollegger, G. and Wiemeyer, J. and Peters, J. and Maeda, G.},
  year = {2018},
  pages = {24},
  file = {/zoteropdf/pdf/ewerton_frontiers2018.pdf}
}

@article{kocOnlineOptimalTrajectory2018,
  title = {Online Optimal Trajectory Generation for Robot Table Tennis},
  volume = {105},
  journal = {Robotics and Autonomous Systems},
  author = {Koc, O. and Maeda, G. and Peters, J.},
  year = {2018},
  pages = {121--137},
  file = {/zoteropdf/pdf/kocOnlineRAS2018.pdf}
}

@article{maedaCombinedILCDisturbance2015,
  title = {Combined {{ILC}} and {{Disturbance Observer}} for the {{Rejection}} of {{Near Repetitive}}-{{Disturbances}}, with {{Application}} to {{Excavation}}},
  volume = {23},
  number = {5},
  journal = {IEEE Transactions on Control Systems Technology},
  author = {Maeda, Guilherme and Manchester, Ian and Rye, David},
  year = {2015},
  pages = {1754--1769},
  file = {/zoteropdf/pdf/Maeda2015Combined ILC Disturbance Observer Rejection Near Repetitive Disturbances Autonomous Excavation.pdf}
}

@article{maedaControlXYNano2006,
  title = {Control of an {{XY}} Nano\textendash{}Positioning Table for a Compact Nano-Machine Tool},
  volume = {49},
  number = {1},
  journal = {JSME International Journal Series C},
  author = {Maeda, G. and Sato, K. and Hashizume, H. and Shinshi, T.},
  year = {2006},
  pages = {21--27},
  file = {/zoteropdf/pdf/maeda2006control of an XY nano positioning table for a compact nano machine tool.pdf}
}

@article{maedaPracticalControlMethod2008,
  title = {Practical Control Method for Ultra-Precision Positioning Using a Ballscrew Mechanism},
  volume = {32},
  number = {4},
  journal = {Precision Engineering},
  author = {Maeda, G.J. and Sato, K.},
  year = {2008},
  keywords = {maeda2008practical Practical control method ultra precision positioning using ballscrew mechanism},
  pages = {309--318},
  file = {/zoteropdf/pdf/maeda2008practical Practical control method  ultra precision positioning using  ballscrew mechanism.PDF}
}

@article{maedaAcquiringGeneralizingEmbodiment2016,
  title = {Acquiring and {{Generalizing}} the {{Embodiment Mapping From Human Observations}} to {{Robot Skills}}},
  volume = {1},
  issn = {2377-3766},
  number = {2},
  journal = {IEEE Robotics and Automation Letters},
  doi = {10.1109/LRA.2016.2525038},
  author = {Maeda, G. and Ewerton, M. and Koert, D. and Peters, J.},
  month = jul,
  year = {2016},
  keywords = {7 degree-of-freedom,DoF arm,embodiment mapping,golf swing,human demonstrator,Human Factors and Human-in-the-Loop,human observations,human-robot structural associations,intelligent robots,kinematic mapping,Kinematics,Learning and Adaptive Systems,marker tracking,Motion and Path Planning,Optimization,Optimization and Optimal Control Maeda2016RAL_Acquiring and Generalizing the Embodiment Mapping From Human Observations to Robot Skills RAL,robot imitation,robot kinematic structure,robot kinematics,Robot kinematics,robot learner,robot reproduction,robot skills,Service robots,Shape,task-specific costs,Trajectory},
  pages = {784-791},
  file = {/zoteropdf/pdf/Maeda2016RAL_Acquiring and Generalizing the Embodiment Mapping From Human Observations to Robot Skills.pdf}
}

@article{lioutikovLearningMovementPrimitive2017,
  title = {Learning Movement Primitive Libraries through Probabilistic Segmentation},
  volume = {36},
  abstract = {Movement primitives are a well-established approach for encoding and executing movements. While the primitives themselves have been extensively researched, the concept of movement primitive libraries has not received similar attention. Libraries of movement primitives represent the skill set of an agent. Primitives can be queried and sequenced in order to solve specific tasks. The goal of this work is to segment unlabeled demonstrations into a representative set of primitives. Our proposed method differs from current approaches by taking advantage of the often neglected, mutual dependencies between the segments contained in the demonstrations and the primitives to be encoded. By exploiting this mutual dependency, we show that we can improve both the segmentation and the movement primitive library. Based on probabilistic inference our novel approach segments the demonstrations while learning a probabilistic representation of movement primitives. We demonstrate our method on two real robot applications. First, the robot segments sequences of different letters into a library, explaining the observed trajectories. Second, the robot segments demonstrations of a chair assembly task into a movement primitive library. The library is subsequently used to assemble the chair in an order not present in the demonstrations.},
  number = {8},
  journal = {The International Journal of Robotics Research},
  doi = {10.1177/0278364917713116},
  author = {Lioutikov, Rudolf and Neumann, Gerhard and Maeda, Guilherme and Peters, Jan},
  year = {2017},
  pages = {879-894},
  file = {/home/gjmaeda/Dropbox/Papers/pdf/lioutikovLearningMovementPrimitive2017.pdf}
}

@article{satoPracticalControlMethod2009,
  title = {A Practical Control Method for Precision Motion \textendash{} {{Improvement}} of {{NCTF}} Control Method for Continuous Motion Control},
  volume = {33},
  number = {2},
  journal = {Precision Engineering},
  author = {Sato, K. and Maeda, G.J.},
  year = {2009},
  pages = {175--186}
}

@article{satoPracticalUltraprecisionPositioning2008,
  title = {Practical {{Ultraprecision Positioning}} of a {{Ball Screw Mechanism}}},
  volume = {9},
  number = {2},
  journal = {International Journal of Precision Engineering and Manufacturing},
  author = {Sato, K. and Maeda, G.J.},
  year = {2008},
  keywords = {sato2008practical Practical Ultraprecision Positioning of a Ball Screw Mechanism},
  pages = {44--49}
}

@article{celeminReinforcementLearningMotor2019,
  title = {Reinforcement {{Learning}} of {{Motor Skills}} Using {{Policy Search}} and {{Human Corrective Advice}}},
  volume = {OnlineFirst},
  journal = {International Journal of Robotics Research (IJRR)},
  author = {Celemin, C. and Maeda, G. and {Ruiz-del-Solar}, J and Peters, J. and Kober, J.},
  year = {2019},
  file = {/zoteropdf/pdf/celemin_accepted_ijrr_2019.pdf},
  note = {celemin\_accepted\_ijrr\_2019}
}

@article{ewerton2019learningFrontiers,
  title = {Learning Trajectory Distributions for Assisted Teleoperation and Path Planning},
  volume = {6},
  number = {89},
  journal = {Frontiers in Robotics and AI},
  author = {Ewerton, Marco and Arenz, Oleg and Maeda, Guilherme and Koert, Dorothea and Kolev, Zlatko and Takahashi, Masaki and Peters, Jan},
  year = {2019},
  file = {/zoteropdf/pdf/ewerton2019learningFrontiers.pdf},
  publisher = {{Frontiers}}
}

@article{maeda_phase2017_IJRR,
  title = {Phase Estimation for Fast Action Recognition and Trajectory Generation in Human\textendash{}Robot Collaboration},
  volume = {36},
  abstract = {This paper proposes a method to achieve fast and fluid human\textendash{}robot interaction by estimating the progress of the movement of the human. The method allows the progress, also referred to as the phase of the movement, to be estimated even when observations of the human are partial and occluded; a problem typically found when using motion capture systems in cluttered environments. By leveraging on the framework of Interaction Probabilistic Movement Primitives, phase estimation makes it possible to classify the human action, and to generate a corresponding robot trajectory before the human finishes his/her movement. The method is therefore suited for semi-autonomous robots acting as assistants and coworkers. Since observations may be sparse, our method is based on computing the probability of different phase candidates to find the phase that best aligns the Interaction Probabilistic Movement Primitives with the current observations. The method is fundamentally different from approaches based on Dynamic Time Warping that must rely on a consistent stream of measurements at runtime. The resulting framework can achieve phase estimation, action recognition and robot trajectory coordination using a single probabilistic representation. We evaluated the method using a seven-degree-of-freedom lightweight robot arm equipped with a five-finger hand in single and multi-task collaborative experiments. We compare the accuracy achieved by phase estimation with our previous method based on dynamic time warping.},
  number = {13-14},
  journal = {The International Journal of Robotics Research},
  doi = {10.1177/0278364917693927},
  author = {Maeda, Guilherme and Ewerton, Marco and Neumann, Gerhard and Lioutikov, Rudolf and Peters, Jan},
  year = {2017},
  pages = {1579-1594},
  eprint = {https://doi.org/10.1177/0278364917693927}
}

@article{Maeda2017AURO,
  title = {Probabilistic Movement Primitives for Coordination of Multiple Human\textendash{}Robot Collaborative Tasks},
  volume = {41},
  issn = {1573-7527},
  abstract = {This paper proposes an interaction learning method for collaborative and assistive robots based on movement primitives. The method allows for both action recognition and human\textendash{}robot movement coordination. It uses imitation learning to construct a mixture model of human\textendash{}robot interaction primitives. This probabilistic model allows the assistive trajectory of the robot to be inferred from human observations. The method is scalable in relation to the number of tasks and can learn nonlinear correlations between the trajectories that describe the human\textendash{}robot interaction. We evaluated the method experimentally with a lightweight robot arm in a variety of assistive scenarios, including the coordinated handover of a bottle to a human, and the collaborative assembly of a toolbox. Potential applications of the method are personal caregiver robots, control of intelligent prosthetic devices, and robot coworkers in factories.},
  number = {3},
  journal = {Autonomous Robots},
  doi = {10.1007/s10514-016-9556-2},
  author = {Maeda, Guilherme J. and Neumann, Gerhard and Ewerton, Marco and Lioutikov, Rudolf and Kroemer, Oliver and Peters, Jan},
  month = mar,
  year = {2017},
  pages = {593-612}
}


